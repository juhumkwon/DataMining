{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIRtDnefeVHa2Ei9a90bwN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/DataMining/blob/main/2_2_AdaBoost_%EC%98%88%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPiy0Zk3YNBL",
        "outputId": "b84b65fc-f8b2-4b20-d580-e46f2cdbfcf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습기 가중치 (alphas): [0.4236489301936017]\n",
            "분할점 (classifiers): [0.35]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터\n",
        "x = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
        "y = np.array([1, 1, 1, -1, -1, -1, -1, 1, 1, 1])\n",
        "\n",
        "# 초기 가중치\n",
        "N = len(x)\n",
        "w = np.ones(N) / N\n",
        "\n",
        "def calculate_entropy(w, y):\n",
        "    \"\"\"가중 엔트로피 계산\"\"\"\n",
        "    total_weight = np.sum(w)\n",
        "    pos_weight = np.sum(w[y == 1])\n",
        "    neg_weight = np.sum(w[y == -1])\n",
        "\n",
        "    if pos_weight == 0 or neg_weight == 0:\n",
        "        return 0\n",
        "\n",
        "    pos_ratio = pos_weight / total_weight\n",
        "    neg_ratio = neg_weight / total_weight\n",
        "\n",
        "    return - (pos_ratio * np.log2(pos_ratio) + neg_ratio * np.log2(neg_ratio))\n",
        "\n",
        "def find_best_split(x, y, w):\n",
        "    \"\"\"최적의 분할점 k 찾기\"\"\"\n",
        "    best_k = None\n",
        "    min_entropy = float('inf')\n",
        "\n",
        "    # 가능한 분할점\n",
        "    thresholds = (x[:-1] + x[1:]) / 2\n",
        "\n",
        "    for k in thresholds:\n",
        "        left_indices = x <= k\n",
        "        right_indices = x > k\n",
        "\n",
        "        left_entropy = calculate_entropy(w[left_indices], y[left_indices])\n",
        "        right_entropy = calculate_entropy(w[right_indices], y[right_indices])\n",
        "\n",
        "        total_entropy = (np.sum(w[left_indices]) * left_entropy +\n",
        "                         np.sum(w[right_indices]) * right_entropy)\n",
        "\n",
        "        if total_entropy < min_entropy:\n",
        "            min_entropy = total_entropy\n",
        "            best_k = k\n",
        "\n",
        "    return best_k, min_entropy\n",
        "\n",
        "def adaboost(x, y, T):\n",
        "    \"\"\"AdaBoost 알고리즘\"\"\"\n",
        "    N = len(x)\n",
        "    w = np.ones(N) / N  # 초기 가중치\n",
        "    alphas = []\n",
        "    classifiers = []\n",
        "\n",
        "    for t in range(T):\n",
        "        # 1. 최적의 분할점 k 찾기\n",
        "        k, _ = find_best_split(x, y, w)\n",
        "\n",
        "        # 2. 약한 학습기 예측\n",
        "        predictions = np.where(x <= k, 1, -1)\n",
        "\n",
        "        # 3. 오류율 계산\n",
        "        error = np.sum(w[predictions != y]) / np.sum(w)\n",
        "\n",
        "        # 오류율이 0.5 이상이면 중단\n",
        "        if error >= 0.5:\n",
        "            break\n",
        "\n",
        "        # 4. 학습기의 가중치(alpha) 계산\n",
        "        alpha = 0.5 * np.log((1 - error) / error)\n",
        "\n",
        "        # 5. 가중치 업데이트\n",
        "        w = w * np.exp(-alpha * y * predictions)\n",
        "        w = w / np.sum(w)  # 정규화\n",
        "\n",
        "        # 6. 학습기 저장\n",
        "        alphas.append(alpha)\n",
        "        classifiers.append(k)\n",
        "\n",
        "    return alphas, classifiers\n",
        "\n",
        "# AdaBoost 실행\n",
        "T = 5  # 최대 반복 수\n",
        "alphas, classifiers = adaboost(x, y, T)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"학습기 가중치 (alphas):\", alphas)\n",
        "print(\"분할점 (classifiers):\", classifiers)\n"
      ]
    }
  ]
}