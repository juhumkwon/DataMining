{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQggZJYEXw++/VUVBcyanh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/DataMining/blob/main/YOLO_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import numpy as np\n",
        "\n",
        "# YOLOv5 Model - Backbone, Detection Head\n",
        "class YOLOv5(Model):\n",
        "    def __init__(self, S=7, B=2, C=20):\n",
        "        super(YOLOv5, self).__init__()\n",
        "        self.S = S  # Grid size\n",
        "        self.B = B  # Number of bounding boxes\n",
        "        self.C = C  # Number of classes\n",
        "\n",
        "        # Backbone: Simple Convolutional Layers (CSPDarknet is simplified)\n",
        "        self.conv1 = layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu')\n",
        "        self.pool1 = layers.MaxPooling2D(pool_size=(2, 2), strides=2)\n",
        "        self.conv2 = layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')\n",
        "        self.pool2 = layers.MaxPooling2D(pool_size=(2, 2), strides=2)\n",
        "        self.conv3 = layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')\n",
        "        self.pool3 = layers.MaxPooling2D(pool_size=(2, 2), strides=2)\n",
        "\n",
        "        # YOLO Head (Detection Layer)\n",
        "        self.detection_head = layers.Conv2D(S * S * (B * 5 + C), (1, 1), activation='linear')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        # Detection output\n",
        "        x = self.detection_head(x)\n",
        "\n",
        "        return tf.reshape(x, (-1, self.S, self.S, self.B * 5 + self.C))\n",
        "\n",
        "# Dummy dataset\n",
        "def create_dataset(num_samples=1000, S=7, B=2, C=20):\n",
        "    # Force NumPy arrays to reside on CPU memory\n",
        "    with tf.device('/CPU:0'):\n",
        "        images = np.random.rand(num_samples, 448, 448, 3).astype(np.float32)  # Random images\n",
        "        labels = np.random.rand(num_samples, S, S, 5 * B + C).astype(np.float32)  # Random labels\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    return dataset.batch(16)\n",
        "\n",
        "# Loss function\n",
        "def yolo_loss(y_true, y_pred, S=7, B=2, C=20):\n",
        "    pred_box = y_pred[..., :5 * B]\n",
        "    pred_class = y_pred[..., 5 * B:]\n",
        "    true_box = y_true[..., :5 * B]\n",
        "    true_class = y_true[..., 5 * B:]\n",
        "\n",
        "    # Objectness loss (confidence)\n",
        "    obj_loss = tf.reduce_mean(tf.square(true_box[..., 4::5] - pred_box[..., 4::5]))\n",
        "\n",
        "    # Coordinate loss\n",
        "    coord_loss = tf.reduce_mean(tf.square(true_box[..., :4] - pred_box[..., :4]))\n",
        "\n",
        "    # Classification loss\n",
        "    class_loss = tf.reduce_mean(tf.square(true_class - pred_class))\n",
        "\n",
        "    total_loss = obj_loss + coord_loss + class_loss\n",
        "    return total_loss\n",
        "\n",
        "# Training function\n",
        "def train_yolov5():\n",
        "    S, B, C = 7, 2, 20\n",
        "    model = YOLOv5(S, B, C)\n",
        "    dataset = create_dataset()\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss=lambda y_true, y_pred: yolo_loss(y_true, y_pred, S, B, C))\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Starting training...\")\n",
        "    model.fit(dataset, epochs=10)\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "# Post-processing: Non-Maximum Suppression (NMS)\n",
        "def non_max_suppression(boxes, scores, iou_threshold=0.5):\n",
        "    selected_indices = tf.image.non_max_suppression(boxes, scores, max_output_size=10, iou_threshold=iou_threshold)\n",
        "    return tf.gather(boxes, selected_indices)\n",
        "\n",
        "# Prediction Example\n",
        "def predict_yolov5():\n",
        "    S, B, C = 7, 2, 20\n",
        "    model = YOLOv5(S, B, C)\n",
        "    model.build(input_shape=(None, 448, 448, 3))\n",
        "\n",
        "    # Generate a dummy image for prediction\n",
        "    image = np.random.rand(1, 448, 448, 3).astype(np.float32)\n",
        "    prediction = model(image)\n",
        "\n",
        "    # Decode and apply NMS\n",
        "    boxes = tf.random.uniform((10, 4))  # Random boxes (x_min, y_min, x_max, y_max)\n",
        "    scores = tf.random.uniform((10,))  # Random confidence scores\n",
        "    selected_boxes = non_max_suppression(boxes, scores)\n",
        "\n",
        "    print(\"Selected Boxes (after NMS):\", selected_boxes)\n",
        "\n",
        "# Main Execution\n",
        "if __name__ == \"__main__\":\n",
        "    train_yolov5()\n",
        "    predict_yolov5()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "VuXa9eNIQHhv",
        "outputId": "08bd0fdf-a20e-445b-9a64-051a36998226"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node compile_loss/lambda/sub defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [16,7,7,2] vs. [50176,7,7,2]\n\t [[{{node compile_loss/lambda/sub}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_1757[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_1816]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2d8d1c390a91>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# Main Execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mtrain_yolov5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0mpredict_yolov5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-2d8d1c390a91>\u001b[0m in \u001b[0;36mtrain_yolov5\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/lambda/sub defined at (most recent call last):\n<stack traces unavailable>\nIncompatible shapes: [16,7,7,2] vs. [50176,7,7,2]\n\t [[{{node compile_loss/lambda/sub}}]]\n\ttf2xla conversion failed while converting __inference_one_step_on_data_1757[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_1816]"
          ]
        }
      ]
    }
  ]
}