{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxv1HQM3Dp68l9tsN6Xs/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juhumkwon/DataMining/blob/main/2_2_AdaBoost_%EA%B3%84%EC%82%B0%EA%B3%BC%EC%A0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jA_5FcjZ7TM",
        "outputId": "3aac982d-7609-405f-8e89-10330f8bc218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 반복 1 ===\n",
            "선택된 최적의 분할점: k=0.35\n",
            "훈련 결과: 분할점 k=0.35, 예측=[ 1  1  1 -1 -1 -1 -1 -1 -1 -1], 오류율=0.3000\n",
            "학습기 가중치(alpha): 0.4236\n",
            "업데이트된 가중치: [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857\n",
            " 0.07142857 0.16666667 0.16666667 0.16666667]\n",
            "\n",
            "=== 반복 2 ===\n",
            "선택된 최적의 분할점: k=0.75\n",
            "훈련 결과: 분할점 k=0.75, 예측=[ 1  1  1  1  1  1  1 -1 -1 -1], 오류율=0.7857\n",
            "오류율이 0.5 이상입니다. 알고리즘을 중단합니다.\n",
            "\n",
            "최종 학습기 가중치 (alphas): [0.4236489301936017]\n",
            "최종 분할점 (classifiers): [0.35]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 데이터\n",
        "x = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
        "y = np.array([1, 1, 1, -1, -1, -1, -1, 1, 1, 1])\n",
        "\n",
        "# 초기 가중치\n",
        "N = len(x)\n",
        "w = np.ones(N) / N\n",
        "\n",
        "def calculate_entropy(w, y):\n",
        "    \"\"\"가중 엔트로피 계산\"\"\"\n",
        "    total_weight = np.sum(w)\n",
        "    pos_weight = np.sum(w[y == 1])\n",
        "    neg_weight = np.sum(w[y == -1])\n",
        "\n",
        "    if pos_weight == 0 or neg_weight == 0:\n",
        "        return 0\n",
        "\n",
        "    pos_ratio = pos_weight / total_weight\n",
        "    neg_ratio = neg_weight / total_weight\n",
        "\n",
        "    return - (pos_ratio * np.log2(pos_ratio) + neg_ratio * np.log2(neg_ratio))\n",
        "\n",
        "def find_best_split(x, y, w):\n",
        "    \"\"\"최적의 분할점 k 찾기\"\"\"\n",
        "    best_k = None\n",
        "    min_entropy = float('inf')\n",
        "\n",
        "    # 가능한 분할점\n",
        "    thresholds = (x[:-1] + x[1:]) / 2\n",
        "\n",
        "    for k in thresholds:\n",
        "        left_indices = x <= k\n",
        "        right_indices = x > k\n",
        "\n",
        "        left_entropy = calculate_entropy(w[left_indices], y[left_indices])\n",
        "        right_entropy = calculate_entropy(w[right_indices], y[right_indices])\n",
        "\n",
        "        total_entropy = (np.sum(w[left_indices]) * left_entropy +\n",
        "                         np.sum(w[right_indices]) * right_entropy)\n",
        "\n",
        "        if total_entropy < min_entropy:\n",
        "            min_entropy = total_entropy\n",
        "            best_k = k\n",
        "\n",
        "    return best_k, min_entropy\n",
        "\n",
        "def train_weak_learner(x, y, w, k):\n",
        "    \"\"\"약한 학습기 훈련 과정 출력\"\"\"\n",
        "    predictions = np.where(x <= k, 1, -1)\n",
        "    error = np.sum(w[predictions != y]) / np.sum(w)\n",
        "    print(f\"훈련 결과: 분할점 k={k}, 예측={predictions}, 오류율={error:.4f}\")\n",
        "    return predictions, error\n",
        "\n",
        "def adaboost(x, y, T):\n",
        "    \"\"\"AdaBoost 알고리즘\"\"\"\n",
        "    N = len(x)\n",
        "    w = np.ones(N) / N  # 초기 가중치\n",
        "    alphas = []\n",
        "    classifiers = []\n",
        "\n",
        "    for t in range(T):\n",
        "        print(f\"\\n=== 반복 {t+1} ===\")\n",
        "        # 1. 최적의 분할점 k 찾기\n",
        "        k, _ = find_best_split(x, y, w)\n",
        "        print(f\"선택된 최적의 분할점: k={k}\")\n",
        "\n",
        "        # 2. 약한 학습기 예측\n",
        "        predictions, error = train_weak_learner(x, y, w, k)\n",
        "\n",
        "        # 오류율이 0.5 이상이면 중단\n",
        "        if error >= 0.5:\n",
        "            print(\"오류율이 0.5 이상입니다. 알고리즘을 중단합니다.\")\n",
        "            break\n",
        "\n",
        "        # 3. 학습기의 가중치(alpha) 계산\n",
        "        alpha = 0.5 * np.log((1 - error) / error)\n",
        "        print(f\"학습기 가중치(alpha): {alpha:.4f}\")\n",
        "\n",
        "        # 4. 가중치 업데이트\n",
        "        w = w * np.exp(-alpha * y * predictions)\n",
        "        w = w / np.sum(w)  # 정규화\n",
        "        print(f\"업데이트된 가중치: {w}\")\n",
        "\n",
        "        # 5. 학습기 저장\n",
        "        alphas.append(alpha)\n",
        "        classifiers.append(k)\n",
        "\n",
        "    return alphas, classifiers\n",
        "\n",
        "# AdaBoost 실행\n",
        "T = 5  # 최대 반복 수\n",
        "alphas, classifiers = adaboost(x, y, T)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"\\n최종 학습기 가중치 (alphas):\", alphas)\n",
        "print(\"최종 분할점 (classifiers):\", classifiers)\n"
      ]
    }
  ]
}